{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "using_Convolutions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hari1331/Hari_DS/blob/master/using_Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPZ1bCl03keg",
        "colab_type": "text"
      },
      "source": [
        "**Improving Computer Vision Accuracy using Convolutions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMJIaH833qcU",
        "colab_type": "text"
      },
      "source": [
        "how to do fashion recognition using a Deep Neural Network (DNN) containing three layers \n",
        "-- **the input layer **(in the shape of the data)\n",
        "-- the output layer (in the shape of the desired output)\n",
        "and a hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnCJTdGvnqd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4d1134f-8113-4124-8b19-7c64dd8e9787"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTJbl-yc2344",
        "colab_type": "text"
      },
      "source": [
        "get the Fashion data and load into Train and Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZTxnWDr27JD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "d5983185-a9bb-4d48-f564-1a7d25c1db45"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 11:48:38.077512 140325009549184 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4999 - acc: 0.8253\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3783 - acc: 0.8637\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3394 - acc: 0.8760\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3144 - acc: 0.8850\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2962 - acc: 0.8913\n",
            "10000/10000 [==============================] - 0s 36us/sample - loss: 0.3352 - acc: 0.8809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W8FwZCT3VYw",
        "colab_type": "text"
      },
      "source": [
        "So the lost we got it : 0.8913"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnvJBRih3tRq",
        "colab_type": "text"
      },
      "source": [
        "our accuracy is probably about 89% on training and 87% on validation...not bad..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxqSzfas33Zu",
        "colab_type": "text"
      },
      "source": [
        "**Convolution**s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8cEPgv3z6I",
        "colab_type": "text"
      },
      "source": [
        "how do you make that even better? One way is to use something called Convolutions\n",
        "If you've ever done image processing using a filter (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing)) then convolutions will look very familiar.\n",
        "\n",
        "\n",
        "1.   In short, you take an array (usually 3x3 or 5x5) and pass it over the image. \n",
        "2.   By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection.\n",
        "3.  you'll see a 3x3 that is defined for edge detection where the middle cell is 8,and all of its neighbors are -1.\n",
        "4.  In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor.\n",
        "5.  Do this for every pixel, and you'll end up with a new image that has the edges enhanced.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP0Lo-sB3coD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}